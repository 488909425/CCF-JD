{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\86131\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "c:\\Users\\86131\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "c:\\Users\\86131\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "c:\\Users\\86131\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "import chinese_calendar\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost\n",
    "from sklearn import metrics\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_path(filename:str) -> str:\n",
    "    return str(os.path.dirname(os.getcwd()))+'\\\\data\\\\'+filename+'.csv'\n",
    "\n",
    "\n",
    "def get_time_list(starttime:datetime.datetime,endtime:datetime.datetime):\n",
    "    time_list = []\n",
    "    while starttime<=endtime:\n",
    "        time_list.append(starttime)\n",
    "        starttime += datetime.timedelta(days=1)\n",
    "    return time_list\n",
    "\n",
    "\n",
    "def str_to_datetime(x:str) -> datetime.datetime:\n",
    "    return datetime.datetime.strptime(x, \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col == 'date':\n",
    "            continue   \n",
    "        # elif col=='store_id' or col=='sku_id':\n",
    "        #     df[col] = df[col].astype(int)\n",
    "        # elif col=='online_y' or col=='offline_y':\n",
    "        #     df[col] = df[col].astype(float)\n",
    "        elif col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    # df[col] = df[col].astype(np.float16)\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            # df[col] = df[col].astype('category')\n",
    "            pass\n",
    "    end_mem = df.memory_usage().sum() \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "零售品列表如下： [14, 259, 44, 442, 150, 449, 448, 443]\n",
      "零售品数量为8\n",
      "第1号门店的停售品为：\n",
      "[867, 580, 713, 905, 906, 652, 127, 653, 814, 784, 721, 907, 909, 922, 572, 350, 543]\n",
      "停售种类数量为17\n",
      "第2号门店的停售品为：\n",
      "[865, 866, 451, 580, 8, 713, 586, 936, 652, 653, 693, 601, 350, 543]\n",
      "停售种类数量为14\n",
      "第3号门店的停售品为：\n",
      "[8, 905, 906, 907, 653, 909, 786, 791, 543, 931, 936, 446, 451, 580, 713, 720, 721, 350, 865, 867]\n",
      "停售种类数量为20\n",
      "第4号门店的停售品为：\n",
      "[865, 451, 580, 936, 713, 652, 721, 601, 921, 956, 350, 543]\n",
      "停售种类数量为12\n",
      "第5号门店的停售品为：\n",
      "[865, 866, 995, 580, 8, 713, 586, 905, 906, 907, 909, 956, 569, 127, 350, 543]\n",
      "停售种类数量为16\n",
      "第6号门店的停售品为：\n",
      "[451, 580, 867, 713, 652, 350, 543]\n",
      "停售种类数量为7\n",
      "第7号门店的停售品为：\n",
      "[865, 451, 580, 867, 868, 713, 652, 366, 785, 601, 350, 543]\n",
      "停售种类数量为12\n",
      "第8号门店的停售品为：\n",
      "[865, 451, 580, 867, 931, 713, 586, 652, 653, 785, 958, 309, 601, 795, 956, 350, 543]\n",
      "停售种类数量为17\n",
      "第9号门店的停售品为：\n",
      "[865, 451, 580, 934, 713, 652, 366, 721, 786, 309, 956, 350]\n",
      "停售种类数量为12\n",
      "第10号门店的停售品为：\n",
      "[896, 8, 905, 906, 907, 652, 909, 910, 785, 923, 543, 927, 931, 184, 956, 451, 580, 713, 586, 721, 214, 350, 608, 866, 755]\n",
      "停售种类数量为25\n",
      "第11号门店的停售品为：\n",
      "[451, 580, 796, 867, 868, 8, 713, 586, 956, 652, 996, 814, 721, 693, 922, 540, 350, 543]\n",
      "停售种类数量为18\n",
      "第12号门店的停售品为：\n",
      "[866, 451, 580, 868, 103, 8, 713, 543, 785, 786, 597, 314, 350, 127]\n",
      "停售种类数量为14\n",
      "新品列表如下： [13, 84, 182, 183, 247, 258, 277, 293, 310, 367, 376, 433, 449, 457, 460, 532, 545, 546, 551, 571, 600, 608, 617, 643, 651, 652, 653, 687, 702, 719, 893, 894, 921, 922, 926, 927, 950, 951, 956, 957, 958, 959, 960, 964, 966, 970, 971, 972, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000]\n",
      "新品数量为75\n",
      "线上订单销量中位数小于2的sku种类数量为726\n",
      "线上订单销量中位数小于7的sku种类数量为196\n",
      "线上订单销量中位数小于15的sku种类数量为51\n",
      "线上订单销量中位数大于15的sku种类数量为21\n",
      "线下订单销量中位数小于2的sku种类数量为779\n",
      "线下订单销量中位数小于7的sku种类数量为192\n",
      "线下订单销量中位数小于15的sku种类数量为22\n",
      "线下订单销量中位数大于15的sku种类数量为3\n"
     ]
    }
   ],
   "source": [
    "# 根据历史订单销售数据判定sku类型\n",
    "sku_sales_df = pd.read_csv(get_data_path('sku_sales'), sep=',', encoding='utf8')\n",
    "sku_sales_df['order_time'] = sku_sales_df.apply(func=lambda x: x['order_time'][:10], axis=1)\n",
    "sku_sales_df = sku_sales_df.rename(columns={'order_time':'date'})\n",
    "sku_sales_df['date'] = sku_sales_df['date'].apply(str_to_datetime)\n",
    "\n",
    "# 零售品\n",
    "not_complete_list = sku_sales_df.loc[(sku_sales_df.quantity%1!=0),'sku_id'].unique().tolist()\n",
    "print(\"零售品列表如下：\",not_complete_list)\n",
    "print(f\"零售品数量为{len(not_complete_list)}\")\n",
    "\n",
    "# 预测期每个店铺的停售品\n",
    "not_sale_store_list = []\n",
    "for i in range(1,13):\n",
    "    print(f\"第{i}号门店的停售品为：\")\n",
    "    all_sku_set = set([i for i in range(1,1001)])\n",
    "    condition1 = (sku_sales_df.date>=datetime.datetime(2022,8,15))\n",
    "    condition2 = (sku_sales_df.date<=datetime.datetime(2022,9,30)) \n",
    "    condition3 = (sku_sales_df.date>=datetime.datetime(2023,8,10))\n",
    "    condition4 = (sku_sales_df.store_id==i)\n",
    "    all_sku_set = set([_ for _ in range(1,1001)])\n",
    "    sale_set = set(sku_sales_df.loc[((condition1&condition2) | condition3) & (condition4),'sku_id'].unique().tolist())\n",
    "    not_sale_list = list(all_sku_set-sale_set)\n",
    "    print(not_sale_list)\n",
    "    print(f\"停售种类数量为{len(not_sale_list)}\")\n",
    "    not_sale_store_list.append(not_sale_list)\n",
    "\n",
    "# 新品（历史前一个月无销售记录）\n",
    "new_sale_list = []\n",
    "history_sale_set = set(sku_sales_df.loc[(sku_sales_df.date<datetime.datetime(2023,8,1)),'sku_id'].unique().tolist())\n",
    "new_set = set(sku_sales_df.loc[(sku_sales_df.date>=datetime.datetime(2023,8,1)),'sku_id'].unique().tolist())\n",
    "new_sale_list = [_ for  _ in new_set if _ not in history_sale_set]\n",
    "print(\"新品列表如下：\",new_sale_list)\n",
    "print(f\"新品数量为{len(new_sale_list)}\")\n",
    "\n",
    "\n",
    "# sku销量规模0-2,3-7,8-15,16-inf\n",
    "# 只看历史同期数据\n",
    "condition1 = (sku_sales_df.date>=datetime.datetime(2022,8,25))\n",
    "condition2 = (sku_sales_df.date<=datetime.datetime(2022,9,20)) \n",
    "condition3 = (sku_sales_df.date>=datetime.datetime(2023,8,15))\n",
    "sku_sales_df = sku_sales_df[(condition1 & condition2) | condition3]\n",
    "online_sku_first_sale_list = []\n",
    "online_sku_second_sale_list = []\n",
    "online_sku_third_sale_list = []\n",
    "online_sku_forth_sale_list = []\n",
    "online_sku_sales_df = sku_sales_df[sku_sales_df.channel==2]\n",
    "online_sku_sales_df = online_sku_sales_df.groupby(['store_id','sku_id','date'])[['order_id','quantity']].agg({'order_id':'count','quantity':'sum'}).reset_index()\n",
    "online_sku_sales_df = online_sku_sales_df.groupby('sku_id')['quantity'].median().reset_index()\n",
    "online_sku_sales_df = online_sku_sales_df.sort_values(by='sku_id')\n",
    "tmp_list = online_sku_sales_df.sku_id.tolist()\n",
    "for i in tmp_list:\n",
    "    if online_sku_sales_df.loc[(online_sku_sales_df['sku_id']==i),'quantity'].values<=2:\n",
    "        online_sku_first_sale_list.append(i)\n",
    "    elif online_sku_sales_df.loc[(online_sku_sales_df['sku_id']==i),'quantity'].values<=7:\n",
    "        online_sku_second_sale_list.append(i)\n",
    "    elif online_sku_sales_df.loc[(online_sku_sales_df['sku_id']==i),'quantity'].values<=15:\n",
    "        online_sku_third_sale_list.append(i)\n",
    "    else:\n",
    "        online_sku_forth_sale_list.append(i)\n",
    "print(f\"线上订单销量中位数小于2的sku种类数量为{len(online_sku_first_sale_list)}\")\n",
    "print(f\"线上订单销量中位数小于7的sku种类数量为{len(online_sku_second_sale_list)}\")\n",
    "print(f\"线上订单销量中位数小于15的sku种类数量为{len(online_sku_third_sale_list)}\")\n",
    "print(f\"线上订单销量中位数大于15的sku种类数量为{len(online_sku_forth_sale_list)}\")\n",
    "offline_sku_first_sale_list = []\n",
    "offline_sku_second_sale_list = []\n",
    "offline_sku_third_sale_list = []\n",
    "offline_sku_forth_sale_list = []\n",
    "offline_sku_sales_df = sku_sales_df[sku_sales_df.channel==1]\n",
    "offline_sku_sales_df = offline_sku_sales_df.groupby(['store_id','sku_id','date'])[['order_id','quantity']].agg({'order_id':'count','quantity':'sum'}).reset_index()\n",
    "offline_sku_sales_df = offline_sku_sales_df.groupby('sku_id')['quantity'].median().reset_index()\n",
    "offline_sku_sales_df = offline_sku_sales_df.sort_values(by='sku_id')\n",
    "tmp_list = offline_sku_sales_df.sku_id.tolist()\n",
    "for i in tmp_list:\n",
    "        if offline_sku_sales_df.loc[(offline_sku_sales_df['sku_id']==i),'quantity'].values<=2:\n",
    "            offline_sku_first_sale_list.append(i)\n",
    "        elif offline_sku_sales_df.loc[(offline_sku_sales_df.sku_id==i),'quantity'].values<=7:\n",
    "            offline_sku_second_sale_list.append(i)\n",
    "        elif offline_sku_sales_df.loc[(offline_sku_sales_df.sku_id==i),'quantity'].values<=15:\n",
    "            offline_sku_third_sale_list.append(i)\n",
    "        else:\n",
    "            offline_sku_forth_sale_list.append(i)\n",
    "print(f\"线下订单销量中位数小于2的sku种类数量为{len(offline_sku_first_sale_list)}\")\n",
    "print(f\"线下订单销量中位数小于7的sku种类数量为{len(offline_sku_second_sale_list)}\")\n",
    "print(f\"线下订单销量中位数小于15的sku种类数量为{len(offline_sku_third_sale_list)}\")\n",
    "print(f\"线下订单销量中位数大于15的sku种类数量为{len(offline_sku_forth_sale_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2023, 9, 1, 0, 0),\n",
       " datetime.datetime(2023, 9, 2, 0, 0),\n",
       " datetime.datetime(2023, 9, 3, 0, 0),\n",
       " datetime.datetime(2023, 9, 4, 0, 0),\n",
       " datetime.datetime(2023, 9, 5, 0, 0),\n",
       " datetime.datetime(2023, 9, 6, 0, 0),\n",
       " datetime.datetime(2023, 9, 7, 0, 0),\n",
       " datetime.datetime(2023, 9, 8, 0, 0),\n",
       " datetime.datetime(2023, 9, 9, 0, 0),\n",
       " datetime.datetime(2023, 9, 10, 0, 0),\n",
       " datetime.datetime(2023, 9, 11, 0, 0),\n",
       " datetime.datetime(2023, 9, 12, 0, 0),\n",
       " datetime.datetime(2023, 9, 13, 0, 0),\n",
       " datetime.datetime(2023, 9, 14, 0, 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_start_date = datetime.datetime(2023,9,1) # 预测开始时间\n",
    "predict_end_date = datetime.datetime(2023,9,14)  # 预测结束时间\n",
    "predict_periods = 14 # 预测步长\n",
    "pred_date_list = [] # 预测日期列表\n",
    "tmp = predict_start_date\n",
    "while tmp<=predict_end_date:\n",
    "    pred_date_list.append(tmp)\n",
    "    tmp += datetime.timedelta(days=1)\n",
    "pred_date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "# 训练集数据\n",
    "train_df = pd.read_csv(get_data_path('train_df_V3'))\n",
    "train_df['date'] = train_df['date'].apply(str_to_datetime)\n",
    "# 考虑到可能历史3天里面存在填充数据失真的情况，去掉失真数据部分\n",
    "train_df = train_df[train_df.date>=datetime.datetime(2022,8,21)]\n",
    "train_df = train_df[(train_df.date>=datetime.datetime(2023,7,21)) | (train_df.date<=datetime.datetime(2022,10,15))]\n",
    "\n",
    "# 销售数据(用于测试集，下同)\n",
    "sku_sales_df = pd.read_csv(get_data_path('sku_sales_precess_df_V3'))\n",
    "sku_sales_df['date'] = sku_sales_df['date'].apply(str_to_datetime)\n",
    "\n",
    "# 价格和状态信息\n",
    "sku_price_and_status_df = pd.read_csv(get_data_path('sku_price_and_status'), sep=',', encoding='utf8')\n",
    "# sku_price_and_status_df = sku_price_and_status_df[(sku_price_and_status_df.salable_status==1) & (sku_price_and_status_df.stock_status==1)]\n",
    "sku_price_and_status_df['date'] = sku_price_and_status_df['date'].apply(str_to_datetime)\n",
    "# 成本计算在之前模型训练的时候没加入（是否考虑优化)\n",
    "sku_price_and_status_df = sku_price_and_status_df.sort_values(by=['store_id','sku_id','date'])\n",
    "for i in range(0,7):\n",
    "    sku_price_and_status_df[f'pred_{i}d_price'] = sku_price_and_status_df.groupby(['store_id','sku_id'])['original_price'].shift(i)\n",
    "sku_price_and_status_df = sku_price_and_status_df.fillna(method='backfill')\n",
    "sku_price_and_status_df['unit_cost'] = 0\n",
    "for i in range(7):\n",
    "    sku_price_and_status_df['unit_cost'] += sku_price_and_status_df[f'pred_{i}d_price']\n",
    "    del sku_price_and_status_df[f'pred_{i}d_price']\n",
    "    gc.collect()\n",
    "sku_price_and_status_df['unit_cost'] = round(sku_price_and_status_df['unit_cost']/14,2)\n",
    "sku_price_and_status_df['price_cost_diff'] = round(sku_price_and_status_df['original_price']-sku_price_and_status_df['unit_cost'],2)\n",
    "sku_price_and_status_df['price_cost_cv'] = round(sku_price_and_status_df['price_cost_diff']/sku_price_and_status_df['original_price'],2)\n",
    "\n",
    "# 在V3版本保存好的训练集少了价格和状态信息的三个特征，修正下\n",
    "train_df = pd.merge(left=train_df,\n",
    "                    right=sku_price_and_status_df[['store_id','sku_id','date','unit_cost','price_cost_diff','price_cost_cv']],\n",
    "                    on=['store_id','sku_id','date'],\n",
    "                    how='left')\n",
    "\n",
    "\n",
    "# 加入商品基础信息\n",
    "sku_info_df = pd.read_csv(get_data_path('sku_info'), sep=',', encoding='utf8')\n",
    "\n",
    "# 加入门店天气信息\n",
    "store_weather_df = pd.read_csv(get_data_path('store_weather'), sep=',', encoding='utf8')\n",
    "store_weather_df['date'] = store_weather_df['date'].apply(str_to_datetime)\n",
    "\n",
    "# 获取线上和线下数据\n",
    "online_sku_prom_df = pd.read_csv(get_data_path('online_sku_prom_df'))\n",
    "online_sku_prom_df['date'] = online_sku_prom_df['date'].apply(str_to_datetime)\n",
    "offline_sku_prom_df = pd.read_csv(get_data_path('offline_sku_prom_df'))\n",
    "offline_sku_prom_df['date'] = offline_sku_prom_df['date'].apply(str_to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 初始化相关映射字典以及信息\n",
    "online_store_sku_all_y_mean_dict = {}\n",
    "online_store_sku_all_y_std_dict = {}\n",
    "offline_store_sku_all_y_mean_dict = {}\n",
    "offline_store_sku_all_y_std_dict = {}\n",
    "online_pre_1d_y_dict = {}\n",
    "online_pre_2d_y_dict = {}\n",
    "online_pre_3d_y_dict = {}\n",
    "online_pre_4d_y_dict = {}\n",
    "online_pre_5d_y_dict = {}\n",
    "online_pre_6d_y_dict = {}\n",
    "online_pre_7d_y_dict = {}\n",
    "offline_pre_1d_y_dict = {}\n",
    "offline_pre_2d_y_dict = {}\n",
    "offline_pre_3d_y_dict = {}\n",
    "offline_pre_4d_y_dict = {}\n",
    "offline_pre_5d_y_dict = {}\n",
    "offline_pre_6d_y_dict = {}\n",
    "offline_pre_7d_y_dict = {}\n",
    "\n",
    "\n",
    "for i in range(1,13):\n",
    "    for j in range(1,1001):\n",
    "        part = sku_sales_df[(sku_sales_df.store_id==i) & (sku_sales_df.sku_id==j)]\n",
    "        part = part.sort_values(by=['date'])\n",
    "        hash_key = i*10000+j\n",
    "        if len(part):\n",
    "            online_store_sku_all_y_mean_dict[hash_key] = part['online_store_sku_all_y_mean'].values[0]\n",
    "            online_store_sku_all_y_std_dict[hash_key] = part['online_store_sku_all_y_std'].values[0]\n",
    "            offline_store_sku_all_y_mean_dict[hash_key] = part['offline_store_sku_all_y_mean'].values[0]\n",
    "            offline_store_sku_all_y_std_dict[hash_key] = part['offline_store_sku_all_y_std'].values[0]\n",
    "            online_pre_1d_y_dict[hash_key] = part['online_pre_1d_y'].values[-1]\n",
    "            online_pre_2d_y_dict[hash_key] = part['online_pre_2d_y'].values[-1]\n",
    "            online_pre_3d_y_dict[hash_key] = part['online_pre_3d_y'].values[-1]\n",
    "            online_pre_4d_y_dict[hash_key] = part['online_pre_4d_y'].values[-1]\n",
    "            online_pre_5d_y_dict[hash_key] = part['online_pre_5d_y'].values[-1]\n",
    "            online_pre_6d_y_dict[hash_key] = part['online_pre_6d_y'].values[-1]\n",
    "            online_pre_7d_y_dict[hash_key] = part['online_pre_7d_y'].values[-1]\n",
    "            offline_pre_1d_y_dict[hash_key] = part['offline_pre_1d_y'].values[-1]\n",
    "            offline_pre_2d_y_dict[hash_key] = part['offline_pre_2d_y'].values[-1]\n",
    "            offline_pre_3d_y_dict[hash_key] = part['offline_pre_3d_y'].values[-1]\n",
    "            offline_pre_4d_y_dict[hash_key] = part['offline_pre_4d_y'].values[-1]\n",
    "            offline_pre_5d_y_dict[hash_key] = part['offline_pre_5d_y'].values[-1]\n",
    "            offline_pre_6d_y_dict[hash_key] = part['offline_pre_6d_y'].values[-1]\n",
    "            offline_pre_7d_y_dict[hash_key] = part['offline_pre_7d_y'].values[-1]\n",
    "        else:\n",
    "            for d in [online_store_sku_all_y_mean_dict,online_store_sku_all_y_std_dict,\n",
    "                offline_store_sku_all_y_mean_dict,offline_store_sku_all_y_std_dict,\n",
    "                online_pre_1d_y_dict,online_pre_2d_y_dict,online_pre_3d_y_dict,\n",
    "                online_pre_4d_y_dict,online_pre_5d_y_dict,online_pre_6d_y_dict,online_pre_7d_y_dict,\n",
    "                offline_pre_1d_y_dict,offline_pre_2d_y_dict,offline_pre_3d_y_dict,\n",
    "                offline_pre_4d_y_dict,offline_pre_5d_y_dict,offline_pre_6d_y_dict,offline_pre_7d_y_dict,]:\n",
    "                d[hash_key] = 0\n",
    "\n",
    "\n",
    "mapping_dict = [online_store_sku_all_y_mean_dict,online_store_sku_all_y_std_dict,\n",
    "                offline_store_sku_all_y_mean_dict,offline_store_sku_all_y_std_dict]\n",
    "            \n",
    "mapping_col = ['online_store_sku_all_y_mean','online_store_sku_all_y_std',\n",
    "                'offline_store_sku_all_y_mean','offline_store_sku_all_y_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_0_list = ['online_store_sku_all_y_std','offline_store_sku_all_y_std',\n",
    "             'online_curr_day','online_threshold','online_prom_cur_total_rate',\n",
    "             'offline_curr_day','offline_threshold','offline_prom_cur_total_rate',\n",
    "             'sku_weather_online_y_std','sku_weather_offline_y_std',\n",
    "             'online_store_sku_all_y_cv','offline_store_sku_all_y_cv',\n",
    "             'sku_prom_offline_y_std','sku_prom_online_y_std',\n",
    "             'sku_workday_online_y_std','sku_workday_offline_y_std',\n",
    "             'sku_month_online_y_std','sku_month_offline_y_std',\n",
    "\n",
    "             'unit_cost','price_cost_diff','price_cost_cv'\n",
    "             ]\n",
    "na_M_list = ['online_total_days','offline_total_days',]\n",
    "category_col = ['store_id','sku_id','item_first_cate_cd', 'item_second_cate_cd', 'item_third_cate_cd','brand_code','weather_type',\n",
    "                'online_promotion_type','offline_promotion_type',\n",
    "                'if_new_sale_sku','online_sku_sale_scale','offline_sku_sale_scale',\n",
    "                'month', 'dayofweek','if_workday',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_lightgbm_category_col = ['store_id','sku_id','item_first_cate_cd', 'item_second_cate_cd', 'item_third_cate_cd','brand_code','weather_type',\n",
    "                                'online_promotion_type','month', 'dayofweek','if_workday','if_new_sale_sku','online_sku_sale_scale',]\n",
    "online_lightgbm_numeric_col = ['online_pre_1d_y', 'online_pre_2d_y', 'online_pre_3d_y','online_pre_3d_y_mean', 'online_pre_3d_y_std',\n",
    "                      'online_store_sku_all_y_mean', 'online_store_sku_all_y_std','original_price','min_temperature', 'max_temperature',\n",
    "                      'online_curr_day', 'online_total_days', 'online_threshold', 'online_discount_off',\n",
    "                      'online_prom_cur_total_rate','online_discount_threshold_rate','dayofmonth','dayofyear', \n",
    "                      'sku_online_y_mean', 'sku_online_y_std','sku_online_y_mid','sku_online_y_min', 'sku_online_y_max',\n",
    "                      'original_price_diff', 'original_price_cv','sku_online_y_cv','online_store_sku_all_y_cv',\n",
    "                      'sku_month_online_y_mean','sku_month_online_y_std','sku_month_online_y_mid','sku_month_online_y_max','sku_month_online_y_min',\n",
    "                      'sku_weather_online_y_mean','sku_weather_online_y_std','sku_weather_online_y_mid','sku_weather_online_y_max','sku_weather_online_y_min',\n",
    "                      'sku_prom_online_y_mean','sku_prom_online_y_std','sku_prom_online_y_mid','sku_prom_online_y_max','sku_prom_online_y_min',\n",
    "                      'sku_workday_online_y_mean','sku_workday_online_y_std','sku_workday_online_y_mid','sku_workday_online_y_max','sku_workday_online_y_min',\n",
    "                      'unit_cost','price_cost_diff','price_cost_cv']\n",
    "online_lightgbm_target = ['online_y']\n",
    "online_lightgbm_f = open(str(os.path.dirname(os.getcwd()))+'\\\\model\\\\'+'online_model_lightgbm_3.model','rb').read()  #注意此处model是rb\n",
    "online_lightgbm_model = pickle.loads(online_lightgbm_f)\n",
    "offline_lightgbm_category_col = ['store_id','sku_id','item_first_cate_cd', 'item_second_cate_cd', 'item_third_cate_cd','brand_code','weather_type',\n",
    "                                'offline_promotion_type','month', 'dayofweek','if_workday','if_new_sale_sku','offline_sku_sale_scale',]\n",
    "offline_lightgbm_numeric_col = ['offline_pre_1d_y', 'offline_pre_2d_y', 'offline_pre_3d_y','offline_pre_3d_y_mean', 'offline_pre_3d_y_std',\n",
    "                       'offline_store_sku_all_y_mean', 'offline_store_sku_all_y_std','original_price','min_temperature', 'max_temperature',\n",
    "                       'offline_curr_day','offline_total_days', 'offline_threshold','offline_discount_off',\n",
    "                       'offline_prom_cur_total_rate','offline_discount_threshold_rate', 'dayofmonth','dayofyear', \n",
    "                       'sku_offline_y_mean','sku_offline_y_std', 'sku_offline_y_mid','sku_offline_y_min', 'sku_offline_y_max',\n",
    "                       'original_price_diff', 'original_price_cv','sku_offline_y_cv','offline_store_sku_all_y_cv',\n",
    "                       'sku_month_offline_y_mean','sku_month_offline_y_std','sku_month_offline_y_mid','sku_month_offline_y_max','sku_month_offline_y_min',\n",
    "                       'sku_weather_offline_y_mean','sku_weather_offline_y_std','sku_weather_offline_y_mid','sku_weather_offline_y_max','sku_weather_offline_y_min',\n",
    "                       'sku_prom_offline_y_mean','sku_prom_offline_y_std','sku_prom_offline_y_mid','sku_prom_offline_y_max','sku_prom_offline_y_min',\n",
    "                       'sku_workday_offline_y_mean','sku_workday_offline_y_std','sku_workday_offline_y_mid','sku_workday_offline_y_max','sku_workday_offline_y_min',\n",
    "                       'unit_cost','price_cost_diff','price_cost_cv']\n",
    "offline_lightgbm_target = ['offline_y']\n",
    "offline_lightgbm_f = open(str(os.path.dirname(os.getcwd()))+'\\\\model\\\\'+'offline_model_lightgbm_3.model','rb').read()  #注意此处model是rb\n",
    "offline_lightgbm_model = pickle.loads(offline_lightgbm_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_xgboost_category_col = ['store_id','sku_id','item_first_cate_cd', 'item_second_cate_cd', 'item_third_cate_cd','brand_code','weather_type',\n",
    "                                'online_promotion_type','month', 'dayofweek','if_workday','if_new_sale_sku','online_sku_sale_scale',]\n",
    "online_xgboost_numeric_col = ['online_pre_1d_y', 'online_pre_2d_y', 'online_pre_3d_y','online_pre_3d_y_mean', 'online_pre_3d_y_std',\n",
    "                      'online_store_sku_all_y_mean', 'online_store_sku_all_y_std','original_price','min_temperature', 'max_temperature',\n",
    "                      'online_curr_day', 'online_total_days', 'online_threshold', 'online_discount_off',\n",
    "                      'online_prom_cur_total_rate','online_discount_threshold_rate','dayofmonth','dayofyear', \n",
    "                      'sku_online_y_mean', 'sku_online_y_std','sku_online_y_mid','sku_online_y_min', 'sku_online_y_max',\n",
    "                      'original_price_diff', 'original_price_cv','sku_online_y_cv','online_store_sku_all_y_cv',\n",
    "                      'sku_month_online_y_mean','sku_month_online_y_std','sku_month_online_y_mid','sku_month_online_y_max','sku_month_online_y_min',\n",
    "                      'sku_weather_online_y_mean','sku_weather_online_y_std','sku_weather_online_y_mid','sku_weather_online_y_max','sku_weather_online_y_min',\n",
    "                      'sku_prom_online_y_mean','sku_prom_online_y_std','sku_prom_online_y_mid','sku_prom_online_y_max','sku_prom_online_y_min',\n",
    "                      'sku_workday_online_y_mean','sku_workday_online_y_std','sku_workday_online_y_mid','sku_workday_online_y_max','sku_workday_online_y_min',\n",
    "                      'unit_cost','price_cost_diff','price_cost_cv']\n",
    "online_xgboost_target = ['online_y_log']\n",
    "online_xgboost_enc = None #后续处理\n",
    "online_xgboost_f = open(str(os.path.dirname(os.getcwd()))+'\\\\model\\\\'+'online_model_xgboost_3.model','rb').read()  #注意此处model是rb\n",
    "online_xgboost_model = pickle.loads(online_xgboost_f)\n",
    "\n",
    "offline_xgboost_category_col = ['store_id','sku_id','item_first_cate_cd', 'item_second_cate_cd', 'item_third_cate_cd','brand_code','weather_type',\n",
    "                                'offline_promotion_type','month', 'dayofweek','if_workday','if_new_sale_sku','offline_sku_sale_scale',]\n",
    "offline_xgboost_numeric_col = ['offline_pre_1d_y', 'offline_pre_2d_y', 'offline_pre_3d_y','offline_pre_3d_y_mean', 'offline_pre_3d_y_std',\n",
    "                       'offline_store_sku_all_y_mean', 'offline_store_sku_all_y_std','original_price','min_temperature', 'max_temperature',\n",
    "                       'offline_curr_day','offline_total_days', 'offline_threshold','offline_discount_off',\n",
    "                       'offline_prom_cur_total_rate','offline_discount_threshold_rate', 'dayofmonth','dayofyear', \n",
    "                       'sku_offline_y_mean','sku_offline_y_std', 'sku_offline_y_mid','sku_offline_y_min', 'sku_offline_y_max',\n",
    "                       'original_price_diff', 'original_price_cv','sku_offline_y_cv','offline_store_sku_all_y_cv',\n",
    "                       'sku_month_offline_y_mean','sku_month_offline_y_std','sku_month_offline_y_mid','sku_month_offline_y_max','sku_month_offline_y_min',\n",
    "                       'sku_weather_offline_y_mean','sku_weather_offline_y_std','sku_weather_offline_y_mid','sku_weather_offline_y_max','sku_weather_offline_y_min',\n",
    "                       'sku_prom_offline_y_mean','sku_prom_offline_y_std','sku_prom_offline_y_mid','sku_prom_offline_y_max','sku_prom_offline_y_min',\n",
    "                       'sku_workday_offline_y_mean','sku_workday_offline_y_std','sku_workday_offline_y_mid','sku_workday_offline_y_max','sku_workday_offline_y_min',\n",
    "                       'unit_cost','price_cost_diff','price_cost_cv']\n",
    "offline_xgboost_target = ['offline_y_log']\n",
    "offline_xgboost_enc = None #后续处理\n",
    "offline_xgboost_f = open(str(os.path.dirname(os.getcwd()))+'\\\\model\\\\'+'offline_model_xgboost_3.model','rb').read()  #注意此处model是rb\n",
    "offline_xgboost_model = pickle.loads(offline_xgboost_f)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_catboost_category_col = ['store_id','sku_id','weather_type',\n",
    "                                'online_promotion_type','month', 'dayofweek','if_workday','if_new_sale_sku','online_sku_sale_scale',]\n",
    "online_catboost_numeric_col = ['online_pre_1d_y', 'online_pre_2d_y', 'online_pre_3d_y','online_pre_3d_y_mean', 'online_pre_3d_y_std',\n",
    "                      'original_price','min_temperature', 'max_temperature',\n",
    "                      'online_curr_day', 'online_total_days', 'online_threshold', 'online_discount_off',\n",
    "                      'online_prom_cur_total_rate','online_discount_threshold_rate','dayofmonth','dayofyear', \n",
    "                      'sku_online_y_mid',\n",
    "                      'original_price_diff', 'original_price_cv','sku_online_y_cv','online_store_sku_all_y_cv',\n",
    "                      'sku_month_online_y_mid',\n",
    "                      'sku_weather_online_y_mid',\n",
    "                      'sku_prom_online_y_mid',\n",
    "                      'sku_workday_online_y_mid',\n",
    "                      'unit_cost','price_cost_diff','price_cost_cv']\n",
    "online_catboost_target = ['online_y_log']\n",
    "online_catboost_f = open(str(os.path.dirname(os.getcwd()))+'\\\\model\\\\'+'online_model_catboost_3.model','rb').read()  #注意此处model是rb\n",
    "online_catboost_model = pickle.loads(online_catboost_f)\n",
    "\n",
    "offline_catboost_category_col = ['store_id','sku_id', 'weather_type',\n",
    "                                'offline_promotion_type','month', 'dayofweek','if_workday','if_new_sale_sku','offline_sku_sale_scale',]\n",
    "offline_catboost_numeric_col = ['offline_pre_1d_y', 'offline_pre_2d_y', 'offline_pre_3d_y','offline_pre_3d_y_mean', 'offline_pre_3d_y_std',\n",
    "                       'original_price','min_temperature', 'max_temperature',\n",
    "                       'offline_curr_day','offline_total_days', 'offline_threshold','offline_discount_off',\n",
    "                       'offline_prom_cur_total_rate','offline_discount_threshold_rate', 'dayofmonth','dayofyear', \n",
    "                       'sku_offline_y_mid',\n",
    "                       'original_price_diff', 'original_price_cv','sku_offline_y_cv','offline_store_sku_all_y_cv',\n",
    "                       'sku_month_offline_y_mid',\n",
    "                       'sku_weather_offline_y_mid',\n",
    "                       'sku_prom_offline_y_mid',\n",
    "                       'sku_workday_offline_y_mid',\n",
    "                       'unit_cost','price_cost_diff','price_cost_cv']\n",
    "offline_catboost_target = ['offline_y_log']\n",
    "offline_catboost_f = open(str(os.path.dirname(os.getcwd()))+'\\\\model\\\\'+'offline_model_catboost_3.model','rb').read()  #注意此处model是rb\n",
    "offline_catboost_model = pickle.loads(offline_catboost_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_stacking_category_col = ['item_third_cate_cd','weather_type',\n",
    "                                'dayofweek','online_sku_sale_scale',]\n",
    "online_stacking_numeric_col = ['online_pre_1d_y', 'online_pre_2d_y', 'online_pre_3d_y', 'online_pre_4d_y', 'online_pre_5d_y',\n",
    "                      'original_price','min_temperature', 'max_temperature',\n",
    "                      'online_curr_day', 'online_discount_off',\n",
    "                      'online_prom_cur_total_rate',\n",
    "                      'sku_online_y_mean','sku_online_y_mid', 'sku_online_y_max',\n",
    "                      'original_price_diff', 'original_price_cv','sku_online_y_cv',\n",
    "                      'sku_month_online_y_mid','sku_month_online_y_max',\n",
    "                      'sku_weather_online_y_mid','sku_weather_online_y_max',\n",
    "                      'sku_prom_online_y_mid','sku_prom_online_y_max','sku_prom_online_y_min',\n",
    "                      'sku_workday_online_y_mid',\n",
    "                      'online_y_catboost_log','online_y_lightgbm_log','online_y_xgboost_log',\n",
    "                      'online_y_min_log','online_y_diff_log',\n",
    "                      'online_y_min','online_y_diff',\n",
    "                      'online_y_log_pred','online_y_pred'\n",
    "                      ]\n",
    "online_stacking_target = ['online_y_label']\n",
    "online_clf_f = open(str(os.path.dirname(os.getcwd()))+'\\\\model\\\\'+'online_clf_model_3.model','rb').read()  #注意此处model是rb\n",
    "online_clf_model = pickle.loads(online_clf_f)\n",
    "\n",
    "offline_stacking_category_col = ['item_third_cate_cd','weather_type',\n",
    "                                'dayofweek','offline_sku_sale_scale',]\n",
    "offline_stacking_numeric_col = ['offline_pre_1d_y', 'offline_pre_2d_y','offline_pre_3d_y','offline_pre_4d_y','offline_pre_5d_y',\n",
    "                       'original_price','min_temperature', 'max_temperature',\n",
    "                       'offline_curr_day','offline_discount_off',\n",
    "                       'offline_prom_cur_total_rate', \n",
    "                       'sku_offline_y_mean', 'sku_offline_y_mid','sku_offline_y_max',\n",
    "                       'original_price_diff', 'original_price_cv','sku_offline_y_cv',\n",
    "                       'sku_month_offline_y_mid','sku_month_offline_y_max',\n",
    "                       'sku_weather_offline_y_mid','sku_weather_offline_y_max',\n",
    "                       'sku_prom_offline_y_mid','sku_prom_offline_y_max','sku_prom_offline_y_min',\n",
    "                       'sku_workday_offline_y_mid',\n",
    "                       'offline_y_catboost_log','offline_y_lightgbm_log','offline_y_xgboost_log',\n",
    "                       'offline_y_min_log','offline_y_diff_log',\n",
    "                       'offline_y_min','offline_y_diff',\n",
    "                       'offline_y_log_pred','offline_y_pred'\n",
    "                       ]\n",
    "offline_stacking_target = ['offline_y_label']\n",
    "offline_clf_f = open(str(os.path.dirname(os.getcwd()))+'\\\\model\\\\'+'offline_clf_model_3.model','rb').read()  #注意此处model是rb\n",
    "offline_clf_model = pickle.loads(offline_clf_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前正在预测2023-09-01 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-02 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-03 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-04 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-05 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-06 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-07 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-08 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-09 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-10 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-11 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-12 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-13 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n",
      "目前正在预测2023-09-14 00:00:00的数据.....\n",
      "Memory usage of dataframe is 12378840.00 MB\n",
      "Memory usage after optimization is: 6105455.00 MB\n",
      "Decreased by 50.7%\n"
     ]
    }
   ],
   "source": [
    "test_df_list = []\n",
    "for dt,d in enumerate(pred_date_list):\n",
    "    print(f\"目前正在预测{pred_date_list[dt]}的数据.....\")\n",
    "    # 滚动更新前7天的销量数据\n",
    "    online_pre_7d_y_dict = online_pre_6d_y_dict\n",
    "    online_pre_6d_y_dict = online_pre_5d_y_dict\n",
    "    online_pre_5d_y_dict = online_pre_4d_y_dict\n",
    "    online_pre_4d_y_dict = online_pre_3d_y_dict\n",
    "    online_pre_3d_y_dict = online_pre_2d_y_dict\n",
    "    online_pre_2d_y_dict = online_pre_1d_y_dict\n",
    "    online_pre_1d_y_dict = {}\n",
    "    offline_pre_7d_y_dict = offline_pre_6d_y_dict\n",
    "    offline_pre_6d_y_dict = offline_pre_5d_y_dict\n",
    "    offline_pre_5d_y_dict = offline_pre_4d_y_dict\n",
    "    offline_pre_4d_y_dict = offline_pre_3d_y_dict\n",
    "    offline_pre_3d_y_dict = offline_pre_2d_y_dict\n",
    "    offline_pre_2d_y_dict = offline_pre_1d_y_dict\n",
    "    offline_pre_1d_y_dict = {}\n",
    "    pre_1d_sku_sales_df = sku_sales_df[sku_sales_df.date==pred_date_list[dt]+datetime.timedelta(-1)]\n",
    "    for i in range(1,13):\n",
    "        for j in range(1,1001):\n",
    "            part = pre_1d_sku_sales_df[(pre_1d_sku_sales_df.store_id==i) & (pre_1d_sku_sales_df.sku_id==j)]\n",
    "            part = part.sort_values(by=['date'])\n",
    "            hash_key = i*10000+j\n",
    "            if len(part)>0:\n",
    "                online_pre_1d_y_dict[hash_key] = part['online_y'].values[-1]\n",
    "                offline_pre_1d_y_dict[hash_key] = part['offline_y'].values[-1]\n",
    "            else:\n",
    "                online_pre_1d_y_dict[hash_key] = 0\n",
    "                offline_pre_1d_y_dict[hash_key] = 0\n",
    "    update_dict_list = [online_pre_1d_y_dict,online_pre_2d_y_dict,online_pre_3d_y_dict,\n",
    "                        online_pre_4d_y_dict,online_pre_5d_y_dict,online_pre_6d_y_dict,online_pre_7d_y_dict,\n",
    "                        offline_pre_1d_y_dict,offline_pre_2d_y_dict,offline_pre_3d_y_dict,\n",
    "                        offline_pre_4d_y_dict,offline_pre_5d_y_dict,offline_pre_6d_y_dict,offline_pre_7d_y_dict,]\n",
    "    update_dict_col_list = ['online_pre_1d_y','online_pre_2d_y','online_pre_3d_y',\n",
    "                            'online_pre_4d_y','online_pre_5d_y','online_pre_6d_y','online_pre_7d_y',\n",
    "                            'offline_pre_1d_y','offline_pre_2d_y','offline_pre_3d_y',\n",
    "                            'offline_pre_4d_y','offline_pre_5d_y','offline_pre_6d_y','offline_pre_7d_y',]\n",
    "\n",
    "    # 初始化当天的测试数据\n",
    "    dt_sales_df = pd.DataFrame(data=None,columns = sku_sales_df.columns)\n",
    "    dt_sales_df['store_id'] = [i for i in range(1,13) for _ in range(1,1001)]\n",
    "    dt_sales_df['sku_id'] = [i for _ in range(1,13) for i in range(1,1001)]\n",
    "    dt_sales_df['date'] = pred_date_list[dt]\n",
    "    for idx,col in enumerate(mapping_col):\n",
    "        dt_sales_df[col] = dt_sales_df['store_id']*10000 + dt_sales_df['sku_id']\n",
    "        dt_sales_df[col] = dt_sales_df[col].map(mapping_dict[idx])\n",
    "        dt_sales_df[col] = dt_sales_df[col].astype(float)\n",
    "    for idx,col in enumerate(update_dict_col_list):\n",
    "        dt_sales_df[col] = 10000*dt_sales_df['store_id']+dt_sales_df['sku_id']\n",
    "        dt_sales_df[col] = dt_sales_df[col].map(update_dict_list[idx])\n",
    "        dt_sales_df[col] = dt_sales_df[col].astype(float) # 出现一个奇怪的问题是online_pre_1d_y会变成object类型，因此这里做类型转换\n",
    "\n",
    "    dt_sales_df['online_pre_3d_y_mean'] = round(dt_sales_df[[f'online_pre_{k}d_y' for k in range(1,4)]].mean(axis=1),2)\n",
    "    dt_sales_df['online_pre_3d_y_std'] = round(dt_sales_df[[f'online_pre_{k}d_y' for k in range(1,4)]].std(axis=1),2)\n",
    "    dt_sales_df['offline_pre_3d_y_mean'] = round(dt_sales_df[[f'offline_pre_{k}d_y' for k in range(1,4)]].mean(axis=1),2)\n",
    "    dt_sales_df['offline_pre_3d_y_std'] = round(dt_sales_df[[f'offline_pre_{k}d_y' for k in range(1,4)]].std(axis=1),2)\n",
    "    dt_sales_df['online_pre_7d_y_mean'] = round(dt_sales_df[[f'online_pre_{k}d_y' for k in range(1,8)]].mean(axis=1),2)\n",
    "    dt_sales_df['online_pre_7d_y_std'] = round(dt_sales_df[[f'online_pre_{k}d_y' for k in range(1,8)]].std(axis=1),2)\n",
    "    dt_sales_df['offline_pre_7d_y_mean'] = round(dt_sales_df[[f'offline_pre_{k}d_y' for k in range(1,8)]].mean(axis=1),2)\n",
    "    dt_sales_df['offline_pre_7d_y_std'] = round(dt_sales_df[[f'offline_pre_{k}d_y' for k in range(1,8)]].std(axis=1),2)\n",
    "\n",
    "    # 合并其他维度特征数据\n",
    "    t1 = sku_price_and_status_df[sku_price_and_status_df.date==pred_date_list[dt]]\n",
    "    t2 = pd.merge(left=dt_sales_df,right=t1,on=['date','store_id','sku_id'],how='left')\n",
    "    t2 = t2[~t2.original_price.isna()] # 过滤无价格字段,最后填充该行数据销量为0\n",
    "    t3 = pd.merge(left=t2,right=sku_info_df,on=['sku_id'],how='left')\n",
    "    t4 = pd.merge(left=t3,right=store_weather_df,on=['store_id','date'],how='left')\n",
    "    t5 = pd.merge(left=t4, right=online_sku_prom_df,on=['store_id','sku_id','date'],how='left')\n",
    "    t5 = pd.merge(left=t5,right=offline_sku_prom_df,on=['store_id','sku_id','date'],how='left')\n",
    "    \n",
    "\n",
    "    # 有意义的缺失值填充\n",
    "    for col in ['offline_discount_off','online_discount_off','offline_discount_threshold_rate','online_discount_threshold_rate']:\n",
    "        t5[col] = t5[col].fillna(0)\n",
    "    for col in ['offline_promotion_type','online_promotion_type']:\n",
    "        t5[col] = t5[col].fillna(-1)\n",
    "\n",
    "\n",
    "    # sku业务特征\n",
    "    t5['if_new_sale_sku'] = 0\n",
    "    t5.loc[t5['sku_id'].isin(new_sale_list),'if_new_sale_sku'] = 1\n",
    "    t5['online_sku_sale_scale'] = 1\n",
    "    t5.loc[t5['sku_id'].isin(online_sku_second_sale_list),'online_sku_sale_scale'] = 2\n",
    "    t5.loc[t5['sku_id'].isin(online_sku_third_sale_list),'online_sku_sale_scale'] = 3\n",
    "    t5.loc[t5['sku_id'].isin(online_sku_forth_sale_list),'online_sku_sale_scale'] = 4\n",
    "    t5['offline_sku_sale_scale'] = 1\n",
    "    t5.loc[t5['sku_id'].isin(offline_sku_second_sale_list),'offline_sku_sale_scale'] = 2\n",
    "    t5.loc[t5['sku_id'].isin(offline_sku_third_sale_list),'offline_sku_sale_scale'] = 3\n",
    "    t5.loc[t5['sku_id'].isin(offline_sku_forth_sale_list),'offline_sku_sale_scale'] = 4\n",
    "\n",
    "    # 时间特征\n",
    "    t5['month'] = t5['date'].dt.month\n",
    "    t5['dayofweek'] = t5['date'].dt.day_of_week\n",
    "    t5['dayofmonth'] = t5['date'].dt.day\n",
    "    t5['dayofyear'] = t5['date'].dt.day_of_year\n",
    "    t5['if_workday'] = t5['date'].apply(func=lambda x:1 if chinese_calendar.is_workday(x) else 0)\n",
    "\n",
    "    # onehot编码\n",
    "    if online_xgboost_enc is None or offline_xgboost_enc is None:\n",
    "        train_df['month'] = train_df['date'].dt.month\n",
    "        train_df['dayofweek'] = train_df['date'].dt.day_of_week\n",
    "        train_df['if_workday'] = train_df['date'].apply(func=lambda x:1 if chinese_calendar.is_workday(x) else 0)\n",
    "        train_df['if_new_sale_sku'] = 0\n",
    "        train_df.loc[train_df['sku_id'].isin(new_sale_list),'if_new_sale_sku'] = 1\n",
    "        train_df['online_sku_sale_scale'] = 1\n",
    "        train_df.loc[train_df['sku_id'].isin(online_sku_second_sale_list),'online_sku_sale_scale'] = 2\n",
    "        train_df.loc[train_df['sku_id'].isin(online_sku_third_sale_list),'online_sku_sale_scale'] = 3\n",
    "        train_df.loc[train_df['sku_id'].isin(online_sku_forth_sale_list),'online_sku_sale_scale'] = 4\n",
    "        train_df['offline_sku_sale_scale'] = 1\n",
    "        train_df.loc[train_df['sku_id'].isin(offline_sku_second_sale_list),'offline_sku_sale_scale'] = 2\n",
    "        train_df.loc[train_df['sku_id'].isin(offline_sku_third_sale_list),'offline_sku_sale_scale'] = 3\n",
    "        train_df.loc[train_df['sku_id'].isin(offline_sku_forth_sale_list),'offline_sku_sale_scale'] = 4\n",
    "        train_df['offline_y_log'] = np.log(train_df['offline_y']+1)\n",
    "        train_df['online_y_log'] = np.log(train_df['online_y']+1)\n",
    "        online_xgboost_enc = OrdinalEncoder()\n",
    "        online_xgboost_enc.fit_transform(X=train_df.loc[:,online_xgboost_category_col], \n",
    "                                         y=train_df.loc[:,online_xgboost_target])\n",
    "        offline_xgboost_enc = OrdinalEncoder()\n",
    "        offline_xgboost_enc.fit_transform(X=train_df.loc[:,offline_xgboost_category_col], \n",
    "                                         y=train_df.loc[:,offline_xgboost_target])\n",
    "    \n",
    "    # 空间特征\n",
    "    tmp = train_df.groupby('sku_id')['online_y'].agg(['mean','std','median','min','max']).reset_index().rename(columns={'mean':'sku_online_y_mean',\n",
    "                                                                                                            'std':'sku_online_y_std',\n",
    "                                                                                                            'median':'sku_online_y_mid',\n",
    "                                                                                                            'min':'sku_online_y_min',\n",
    "                                                                                                            'max':'sku_online_y_max',}).round(2)\n",
    "    tmp1 = train_df.groupby('sku_id')['offline_y'].agg(['mean','std','median','min','max']).reset_index().rename(columns={'mean':'sku_offline_y_mean',\n",
    "                                                                                                            'std':'sku_offline_y_std',\n",
    "                                                                                                            'median':'sku_offline_y_mid',\n",
    "                                                                                                            'min':'sku_offline_y_min',\n",
    "                                                                                                            'max':'sku_offline_y_max',}).round(2)\n",
    "    tmp2 = train_df.groupby('sku_id')['original_price'].agg(['mean','std','median','min','max']).reset_index().rename(columns={'mean':'sku_original_price_mean',\n",
    "                                                                                                            'std':'sku_original_price_std',\n",
    "                                                                                                            'median':'sku_original_price_mid',\n",
    "                                                                                                            'min':'sku_original_price_min',\n",
    "                                                                                                            'max':'sku_original_price_max',}).round(2)\n",
    "    train_df['month'] = train_df['date'].dt.month\n",
    "    tmp3 = train_df.groupby(['sku_id','month'])['online_y'].agg(['mean','std','median','min','max']).reset_index().rename(columns={'mean':'sku_month_online_y_mean',\n",
    "                                                                                                            'std':'sku_month_online_y_std',\n",
    "                                                                                                                'median':'sku_month_online_y_mid',\n",
    "                                                                                                            'min':'sku_month_online_y_min',\n",
    "                                                                                                            'max':'sku_month_online_y_max',}).round(2)\n",
    "    tmp4 = train_df.groupby(['sku_id','month'])['offline_y'].agg(['mean','std','median','min','max']).reset_index().rename(columns={'mean':'sku_month_offline_y_mean',\n",
    "                                                                                                            'std':'sku_month_offline_y_std',\n",
    "                                                                                                            'median':'sku_month_offline_y_mid',\n",
    "                                                                                                            'min':'sku_month_offline_y_min',\n",
    "                                                                                                            'max':'sku_month_offline_y_max',}).round(2)\n",
    "    del train_df['month']\n",
    "    tmp5 = train_df.groupby(['sku_id','weather_type'])['online_y'].agg(['mean','std','median','min','max']).reset_index().rename(columns={'mean':'sku_weather_online_y_mean',\n",
    "                                                                                                            'std':'sku_weather_online_y_std',\n",
    "                                                                                                            'median':'sku_weather_online_y_mid',\n",
    "                                                                                                            'min':'sku_weather_online_y_min',\n",
    "                                                                                                            'max':'sku_weather_online_y_max',}).round(2)\n",
    "    tmp6 = train_df.groupby(['sku_id','weather_type'])['offline_y'].agg(['mean','std','median','min','max']).reset_index().rename(columns={'mean':'sku_weather_offline_y_mean',\n",
    "                                                                                                            'std':'sku_weather_offline_y_std',\n",
    "                                                                                                            'median':'sku_weather_offline_y_mid',\n",
    "                                                                                                            'min':'sku_weather_offline_y_min',\n",
    "                                                                                                            'max':'sku_weather_offline_y_max',}).round(2)\n",
    "    tmp7 = train_df.groupby(['sku_id','offline_promotion_type'])['offline_y'].agg(['mean','std','median','min','max']).reset_index().rename(columns={'mean':'sku_prom_offline_y_mean',\n",
    "                                                                                                            'std':'sku_prom_offline_y_std',\n",
    "                                                                                                            'median':'sku_prom_offline_y_mid',\n",
    "                                                                                                            'min':'sku_prom_offline_y_min',\n",
    "                                                                                                            'max':'sku_prom_offline_y_max',}).round(2)\n",
    "    tmp8 = train_df.groupby(['sku_id','online_promotion_type'])['online_y'].agg(['mean','std','median','min','max']).reset_index().rename(columns={'mean':'sku_prom_online_y_mean',\n",
    "                                                                                                            'std':'sku_prom_online_y_std',\n",
    "                                                                                                            'median':'sku_prom_online_y_mid',\n",
    "                                                                                                            'min':'sku_prom_online_y_min',\n",
    "                                                                                                            'max':'sku_prom_online_y_max',}).round(2)\n",
    "    train_df['if_workday'] = train_df['date'].apply(func=lambda x:1 if chinese_calendar.is_workday(x) else 0)\n",
    "    tmp9 = train_df.groupby(['sku_id','if_workday'])['offline_y'].agg(['mean','std','median','min','max']).reset_index().rename(columns={'mean':'sku_workday_offline_y_mean',\n",
    "                                                                                                            'std':'sku_workday_offline_y_std',\n",
    "                                                                                                            'median':'sku_workday_offline_y_mid',\n",
    "                                                                                                            'min':'sku_workday_offline_y_min',\n",
    "                                                                                                            'max':'sku_workday_offline_y_max',}).round(2)\n",
    "    tmp10 = train_df.groupby(['sku_id','if_workday'])['online_y'].agg(['mean','std','median','min','max']).reset_index().rename(columns={'mean':'sku_workday_online_y_mean',\n",
    "                                                                                                            'std':'sku_workday_online_y_std',\n",
    "                                                                                                            'median':'sku_workday_online_y_mid',\n",
    "                                                                                                            'min':'sku_workday_online_y_min',\n",
    "                                                                                                            'max':'sku_workday_online_y_max',}).round(2)\n",
    "    del train_df['if_workday']\n",
    "\n",
    "    all_tmp = pd.merge(left=tmp,right=tmp1,how='inner',on=['sku_id'])\n",
    "    all_tmp = pd.merge(left=all_tmp,right=tmp2,how='left',on=['sku_id'])\n",
    "    test_df = pd.merge(left=t5,right=all_tmp,how='left',on=['sku_id'])\n",
    "    test_df = pd.merge(left=test_df,right=tmp3,how='left',on=['sku_id','month'])\n",
    "    test_df = pd.merge(left=test_df,right=tmp4,how='left',on=['sku_id','month'])\n",
    "    test_df = pd.merge(left=test_df,right=tmp5,how='left',on=['sku_id','weather_type'])\n",
    "    test_df = pd.merge(left=test_df,right=tmp6,how='left',on=['sku_id','weather_type'])\n",
    "    test_df = pd.merge(left=test_df,right=tmp7,how='left',on=['sku_id','offline_promotion_type'])\n",
    "    test_df = pd.merge(left=test_df,right=tmp8,how='left',on=['sku_id','online_promotion_type'])\n",
    "    test_df = pd.merge(left=test_df,right=tmp9,how='left',on=['sku_id','if_workday'])\n",
    "    test_df = pd.merge(left=test_df,right=tmp10,how='left',on=['sku_id','if_workday'])\n",
    "\n",
    "    # 业务特征\n",
    "    test_df['original_price_diff'] = test_df['original_price'] - test_df['sku_original_price_mid']\n",
    "    test_df['original_price_cv'] = round(test_df['original_price_diff']/test_df['sku_original_price_mid'],2)\n",
    "    test_df['sku_online_y_cv'] = round(test_df['sku_online_y_std']/test_df['sku_online_y_mid'],2)\n",
    "    test_df['sku_offline_y_cv'] = round(test_df['sku_offline_y_std']/test_df['sku_offline_y_mid'],2)\n",
    "    test_df['online_store_sku_all_y_cv'] = round(test_df['online_store_sku_all_y_std']/test_df['online_store_sku_all_y_mean'],2)\n",
    "    test_df['offline_store_sku_all_y_cv'] = round(test_df['offline_store_sku_all_y_std']/test_df['offline_store_sku_all_y_mean'],2)\n",
    "\n",
    "    # 缺失值填充\n",
    "    for col in na_0_list:\n",
    "        test_df[col] = test_df[col].fillna(0)\n",
    "    for col in na_M_list:\n",
    "        test_df[col] = test_df[col].fillna(999)\n",
    "    \n",
    "    # 数据内存压缩\n",
    "    test_df = reduce_mem_usage(test_df)\n",
    "\n",
    "    # 类别特征转换\n",
    "    for col in category_col:\n",
    "        test_df[col] = test_df[col].astype(int) #可能在填充缺失值时出现了0.0,1.0的情况\n",
    "        test_df[col] = test_df[col].astype('category')\n",
    "\n",
    "    # 模型预测\n",
    "    # 线上订单部分\n",
    "    online_catboost_x = test_df[online_catboost_category_col+online_catboost_numeric_col] \n",
    "    online_catboost_y = np.exp(online_catboost_model.predict(online_catboost_x))-1\n",
    "    online_lightgbm_x = test_df[online_lightgbm_category_col+online_lightgbm_numeric_col] \n",
    "    online_lightgbm_y = online_lightgbm_model.predict(online_lightgbm_x,num_iteration=online_lightgbm_model.best_iteration_)\n",
    "    online_xgboost_x = test_df[online_xgboost_category_col+online_xgboost_numeric_col]\n",
    "    online_xgboost_x.loc[:,online_xgboost_category_col] = online_xgboost_enc._transform(online_xgboost_x.loc[:,online_xgboost_category_col],\n",
    "                                                                                        handle_unknown='ignore')[0]\n",
    "    # online_xgboost_x.replace([np.inf, -np.inf], 999, inplace=True) \n",
    "    online_xgboost_y = np.exp(online_xgboost_model.predict(xgb.DMatrix(online_xgboost_x,enable_categorical=True),\n",
    "                                                           ntree_limit=online_xgboost_model.best_ntree_limit))-1 \n",
    "\n",
    "    test_df['online_y_3d'] = round(0.5*test_df['online_pre_1d_y']+0.3*test_df['online_pre_2d_y']+0.2*test_df['online_pre_3d_y'],3)\n",
    "    test_df['online_y_7d'] = round((0.2*test_df['online_pre_1d_y']+0.15*test_df['online_pre_2d_y']+0.15*test_df['online_pre_3d_y']+\n",
    "                                  0.1*test_df['online_pre_4d_y']+0.1*test_df['online_pre_5d_y']+0.1*test_df['online_pre_6d_y']+\n",
    "                                  0.2*test_df['online_pre_7d_y']),3)\n",
    "    test_df['online_y_catboost'] = online_catboost_y.round(3)\n",
    "    test_df['online_y_lightgbm'] = online_lightgbm_y.round(3)\n",
    "    test_df['online_y_xgboost'] = online_xgboost_y.round(3)\n",
    "    # # 线上订单模型融合方式1（所有模型预测值取最大）\n",
    "    # test_df['online_y'] = test_df.apply(func=lambda x:max([x['online_y_3d'],x['online_y_7d'],\n",
    "    #                                                        x['online_y_catboost'],\n",
    "    #                                                        x['online_y_lightgbm'],\n",
    "    #                                                        x['online_y_xgboost']]),axis=1)\n",
    "    # # 线上订单模型融合方式2\n",
    "    # test_df['online_y'] = test_df['online_y_lightgbm'].round(1)\n",
    "    # 线上订单模型融合方式3\n",
    "    # 基于预测值构建新特征和最终预测值,用于预测分类\n",
    "    test_df['online_y_catboost_log'] = np.log(test_df['online_y_catboost']+1)\n",
    "    test_df['online_y_catboost_log'] = test_df['online_y_catboost_log'].fillna(0)\n",
    "    test_df['online_y_lightgbm_log'] = np.log(test_df['online_y_lightgbm']+1)\n",
    "    test_df['online_y_lightgbm_log'] = test_df['online_y_lightgbm_log'].fillna(0)\n",
    "    test_df['online_y_xgboost_log'] = np.log(test_df['online_y_xgboost']+1)\n",
    "    test_df['online_y_xgboost_log'] = test_df['online_y_xgboost_log'].fillna(0)\n",
    "    test_df['online_y_min_log'] = test_df[['online_y_catboost_log','online_y_lightgbm_log','online_y_xgboost_log']].min(axis=1)\n",
    "    test_df['online_y_max_log'] = test_df[['online_y_catboost_log','online_y_lightgbm_log','online_y_xgboost_log']].max(axis=1)\n",
    "    test_df['online_y_diff_log'] = test_df['online_y_max_log']-test_df['online_y_min_log']\n",
    "    test_df['online_y_min'] = test_df[['online_y_3d','online_y_7d','online_y_catboost','online_y_lightgbm','online_y_xgboost']].min(axis=1)\n",
    "    test_df['online_y_max'] = test_df[['online_y_3d','online_y_7d','online_y_catboost','online_y_lightgbm','online_y_xgboost']].max(axis=1)\n",
    "    test_df['online_y_diff'] = test_df['online_y_max']-test_df['online_y_min']\n",
    "    test_df['online_y_log_pred'] = test_df[['online_y_catboost_log','online_y_lightgbm_log','online_y_xgboost_log']].mean(axis=1)\n",
    "    test_df['online_y_pred'] = np.exp(test_df['online_y_log_pred'].values)-1\n",
    "    # # 取mean的值效果不理想，直接取max值\n",
    "    # test_df['online_y_log_pred'] = test_df['online_y_max_log']\n",
    "    # test_df['online_y_pred'] = test_df['online_y_max']\n",
    "\n",
    "    online_clf_x = test_df[online_stacking_category_col+online_stacking_numeric_col] \n",
    "    online_y_label_pred = np.where(online_clf_model.predict(online_clf_x,num_iteration=online_clf_model.best_iteration)>=0.5,1,0)\n",
    "    test_df['online_y_label_pred'] = online_y_label_pred\n",
    "\n",
    "    # 根据分类标签结果进行修正（暂不考虑根据模型修正）\n",
    "    test_df['online_y_pred_fix'] = test_df['online_y_pred']\n",
    "    test_df.loc[(test_df.online_y_label_pred==1) & (test_df.online_sku_sale_scale==1),'online_y_pred_fix'] += 0.3\n",
    "    test_df.loc[(test_df.online_y_label_pred==1) & (test_df.online_sku_sale_scale==2),'online_y_pred_fix'] += 0.5\n",
    "    test_df.loc[(test_df.online_y_label_pred==1) & (test_df.online_sku_sale_scale==3),'online_y_pred_fix'] += 1\n",
    "    test_df.loc[(test_df.online_y_label_pred==1) & (test_df.online_sku_sale_scale==4),'online_y_pred_fix'] *= 1.05\n",
    "    # 根据日期进行修正\n",
    "    # 第一个周五/周六\n",
    "    if dt in (0,1):\n",
    "        test_df['online_y_pred_fix'] = test_df[['online_y_pred_fix','online_pre_1d_y','online_pre_7d_y']].max(axis=1)\n",
    "    # 第一个周日,周中\n",
    "    if dt in (2,3,4,5,6):\n",
    "        test_df['online_y_pred_fix'] = test_df[['online_y_pred_fix','online_pre_7d_y']].max(axis=1)\n",
    "    # 第二个周五/周六\n",
    "    if dt in (7,8):\n",
    "        test_df['online_y_pred_fix_backup'] = 0.95*test_df['online_pre_7d_y']\n",
    "        test_df['online_y_pred_fix'] = test_df[['online_y_pred_fix','online_pre_1d_y','online_y_pred_fix_backup']].max(axis=1)\n",
    "        del test_df['online_y_pred_fix_backup']\n",
    "    # 第二个周日,周中\n",
    "    if dt in (9,10,11,12,13):\n",
    "        test_df['online_y_pred_fix_backup'] = 0.95*test_df['online_pre_7d_y']\n",
    "        test_df['online_y_pred_fix'] = test_df[['online_y_pred_fix','online_y_pred_fix_backup']].max(axis=1)\n",
    "        del test_df['online_y_pred_fix_backup']\n",
    "\n",
    "    test_df['online_y'] = test_df['online_y_pred_fix'].round(1)\n",
    "    test_df['online_y'] = test_df.apply(func=lambda x:x['online_y'] if x['online_y']>0 else 0,axis=1)\n",
    "\n",
    "    # 零售品业务处理\n",
    "    test_df['online_y'] = test_df.apply(func=lambda x:x['online_y'] if x['sku_id'] in not_complete_list else round(x['online_y']), axis=1)\n",
    "    \n",
    "   \n",
    "\n",
    "    # 线下订单部分\n",
    "    offline_catboost_x = test_df[offline_catboost_category_col+offline_catboost_numeric_col] \n",
    "    offline_catboost_y = np.exp(offline_catboost_model.predict(offline_catboost_x))-1\n",
    "    offline_lightgbm_x = test_df[offline_lightgbm_category_col+offline_lightgbm_numeric_col] \n",
    "    offline_lightgbm_y = offline_lightgbm_model.predict(offline_lightgbm_x,num_iteration=offline_lightgbm_model.best_iteration_)\n",
    "    offline_xgboost_x = test_df[offline_xgboost_category_col+offline_xgboost_numeric_col] \n",
    "    offline_xgboost_x.loc[:,offline_xgboost_category_col] = offline_xgboost_enc._transform(offline_xgboost_x.loc[:,offline_xgboost_category_col],\n",
    "                                                                                        handle_unknown='ignore')[0]\n",
    "    # offline_xgboost_x.replace([np.inf, -np.inf], 999, inplace=True)\n",
    "    offline_xgboost_y = np.exp(offline_xgboost_model.predict(xgb.DMatrix(offline_xgboost_x,enable_categorical=True),\n",
    "                                                             ntree_limit=offline_xgboost_model.best_ntree_limit))-1 \n",
    "    test_df['offline_y_3d'] = round(0.5*test_df['offline_pre_1d_y']+0.3*test_df['offline_pre_2d_y']+0.2*test_df['offline_pre_3d_y'],3)\n",
    "    test_df['offline_y_7d'] = round((0.2*test_df['offline_pre_1d_y']+0.15*test_df['offline_pre_2d_y']+0.15*test_df['offline_pre_3d_y']+\n",
    "                                  0.1*test_df['offline_pre_4d_y']+0.1*test_df['offline_pre_5d_y']+0.1*test_df['offline_pre_6d_y']+\n",
    "                                  0.2*test_df['offline_pre_7d_y']),3)\n",
    "    test_df['offline_y_catboost'] = offline_catboost_y.round(3)\n",
    "    test_df['offline_y_lightgbm'] = offline_lightgbm_y.round(3)\n",
    "    test_df['offline_y_xgboost'] = offline_xgboost_y.round(3)\n",
    "    # # 线下订单模型融合方式1（所有模型预测值取最大）\n",
    "    # # test_df['offline_y'] = test_df.apply(func=lambda x:max([x['offline_y_3d'],x['offline_y_7d'],\n",
    "    # #                                                        x['offline_y_catboost'],\n",
    "    # #                                                        x['offline_y_lightgbm'],\n",
    "    # #                                                        x['offline_y_xgboost']]),axis=1)\n",
    "    # # 线下订单模型融合方式2\n",
    "    # test_df['offline_y'] = test_df['offline_y_lightgbm']\n",
    "    # 线下订单模型融合方式3\n",
    "    # 用于构建分类模型的线下特征\n",
    "    test_df['offline_y_catboost_log'] = np.log(test_df['offline_y_catboost']+1)\n",
    "    test_df['offline_y_catboost_log'] = test_df['offline_y_catboost_log'].fillna(0)\n",
    "    test_df['offline_y_lightgbm_log'] = np.log(test_df['offline_y_lightgbm']+1)\n",
    "    test_df['offline_y_lightgbm_log'] = test_df['offline_y_lightgbm_log'].fillna(0)\n",
    "    test_df['offline_y_xgboost_log'] = np.log(test_df['offline_y_xgboost']+1)\n",
    "    test_df['offline_y_xgboost_log'] = test_df['offline_y_xgboost_log'].fillna(0)\n",
    "    test_df['offline_y_min_log'] = test_df[['offline_y_catboost_log','offline_y_lightgbm_log','offline_y_xgboost_log']].min(axis=1)\n",
    "    test_df['offline_y_max_log'] = test_df[['offline_y_catboost_log','offline_y_lightgbm_log','offline_y_xgboost_log']].max(axis=1)\n",
    "    test_df['offline_y_diff_log'] = test_df['offline_y_max_log']-test_df['offline_y_min_log']\n",
    "    test_df['offline_y_min'] = test_df[['offline_y_3d','offline_y_7d','offline_y_catboost','offline_y_lightgbm','offline_y_xgboost']].min(axis=1)\n",
    "    test_df['offline_y_max'] = test_df[['offline_y_3d','offline_y_7d','offline_y_catboost','offline_y_lightgbm','offline_y_xgboost']].max(axis=1)\n",
    "    test_df['offline_y_diff'] = test_df['offline_y_max']-test_df['offline_y_min']\n",
    "    test_df['offline_y_log_pred'] = test_df[['offline_y_catboost_log','offline_y_lightgbm_log','offline_y_xgboost_log']].mean(axis=1)\n",
    "    test_df['offline_y_pred'] = np.exp(test_df['offline_y_log_pred'].values)-1\n",
    "    # # 取mean的值效果不理想，直接取max值\n",
    "    # test_df['offline_y_log_pred'] = test_df['offline_y_max_log']\n",
    "    # test_df['offline_y_pred'] = test_df['offline_y_max']\n",
    "\n",
    "    offline_clf_x = test_df[offline_stacking_category_col+offline_stacking_numeric_col] \n",
    "    offline_y_label_pred = np.where(offline_clf_model.predict(offline_clf_x,num_iteration=offline_clf_model.best_iteration)>=0.5,1,0)\n",
    "    test_df['offline_y_label_pred'] = offline_y_label_pred\n",
    "\n",
    "    # 根据结果进行修正（暂不考虑根据模型修正）\n",
    "    test_df['offline_y_pred_fix'] = test_df['offline_y_pred']\n",
    "    test_df.loc[(test_df.offline_y_label_pred==1) & (test_df.offline_sku_sale_scale==1),'offline_y_pred_fix'] += 0.3\n",
    "    test_df.loc[(test_df.offline_y_label_pred==1) & (test_df.offline_sku_sale_scale==2),'offline_y_pred_fix'] += 0.5\n",
    "    test_df.loc[(test_df.offline_y_label_pred==1) & (test_df.offline_sku_sale_scale==3),'offline_y_pred_fix'] += 1\n",
    "    test_df.loc[(test_df.offline_y_label_pred==1) & (test_df.offline_sku_sale_scale==4),'offline_y_pred_fix'] *= 1.05\n",
    "    # 根据日期进行修正\n",
    "    # 第一个周五/周六\n",
    "    if dt in (0,1):\n",
    "        test_df['offline_y_pred_fix'] = test_df[['offline_y_pred_fix','offline_pre_1d_y','offline_pre_7d_y']].max(axis=1)\n",
    "    # 第一个周日,周中\n",
    "    if dt in (2,3,4,5,6):\n",
    "        test_df['offline_y_pred_fix'] = test_df[['offline_y_pred_fix','offline_pre_7d_y']].max(axis=1)\n",
    "    # 第二个周五/周六\n",
    "    if dt in (7,8):\n",
    "        test_df['offline_y_pred_fix_backup'] = 0.95*test_df['offline_pre_7d_y']\n",
    "        test_df['offline_y_pred_fix'] = test_df[['offline_y_pred_fix','offline_pre_1d_y','offline_y_pred_fix_backup']].max(axis=1)\n",
    "        del test_df['offline_y_pred_fix_backup']\n",
    "    # 第二个周日,周中\n",
    "    if dt in (9,10,11,12,13):\n",
    "        test_df['offline_y_pred_fix_backup'] = 0.95*test_df['offline_pre_7d_y']\n",
    "        test_df['offline_y_pred_fix'] = test_df[['offline_y_pred_fix','offline_y_pred_fix_backup']].max(axis=1)\n",
    "        del test_df['offline_y_pred_fix_backup']\n",
    "\n",
    "    test_df['offline_y'] = test_df['offline_y_pred_fix'].round(1)\n",
    "    test_df['offline_y'] = test_df.apply(func=lambda x:x['offline_y'] if x['offline_y']>0 else 0,axis=1)\n",
    "\n",
    "    # 零售品业务处理\n",
    "    test_df['offline_y'] = test_df.apply(func=lambda x:x['offline_y'] if x['sku_id'] in not_complete_list else round(x['offline_y']), axis=1)\n",
    "\n",
    "    # 返回结果\n",
    "    test_df['all_y'] = test_df['online_y']+test_df['offline_y']\n",
    "    test_df_list.append(test_df)\n",
    "\n",
    "    del dt_sales_df['online_y'],dt_sales_df['offline_y'],dt_sales_df['all_y']\n",
    "    gc.collect()\n",
    "    final_dt_sales_df = pd.merge(left=dt_sales_df,\n",
    "                                right=test_df[['store_id','sku_id','date','online_y','offline_y','all_y']],\n",
    "                                on=['store_id','sku_id','date'],\n",
    "                                how='left')\n",
    "    # 停售品业务处理\n",
    "    for i in range(len(not_sale_store_list)):\n",
    "        for j in not_sale_store_list[i]:\n",
    "            for col in ['online_y','offline_y','all_y']:\n",
    "                final_dt_sales_df.loc[((final_dt_sales_df.store_id==i+1) & (final_dt_sales_df.sku_id==j)),col] = 0\n",
    "    # 非售品业务处理\n",
    "    final_dt_sales_df['online_y'] = final_dt_sales_df['online_y'].fillna(0).astype(float)\n",
    "    final_dt_sales_df['offline_y'] = final_dt_sales_df['offline_y'].fillna(0).astype(float)\n",
    "    final_dt_sales_df['all_y'] = final_dt_sales_df['all_y'].fillna(0).astype(float)\n",
    "    final_dt_sales_df = final_dt_sales_df[list(final_dt_sales_df.columns[:3])+list(final_dt_sales_df.columns[-3:])+list(final_dt_sales_df.columns[3:-3])]\n",
    "\n",
    "    # 将预测的结果合并到sku_sale_df,周期滚动训练\n",
    "    sku_sales_df = pd.concat([sku_sales_df,final_dt_sales_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = sku_sales_df[sku_sales_df.date>=datetime.datetime(2023,9,1)]\n",
    "predict_df = predict_df[['date','online_y','offline_y','all_y','store_id','sku_id']].rename(columns={'online_y':'y_online',\n",
    "                                                                                                     'offline_y':'y_offline',\n",
    "                                                                                                     'all_y':'y_all'})\n",
    "predict_df['y_online'] = predict_df.apply(func=lambda x:x['y_online'] if x['y_online']>0 else 0,axis=1)\n",
    "predict_df['y_offline'] = predict_df.apply(func=lambda x:x['y_offline'] if x['y_offline']>0 else 0,axis=1)\n",
    "predict_df['y_all'] = predict_df['y_online']+predict_df['y_offline']\n",
    "predict_df.to_csv(get_data_path('Base_stacking3_predict_df_clf_4'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>y_online</th>\n",
       "      <th>y_offline</th>\n",
       "      <th>y_all</th>\n",
       "      <th>store_id</th>\n",
       "      <th>sku_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>582306</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582307</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582308</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582309</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582310</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750301</th>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750302</th>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750303</th>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750304</th>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750305</th>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  y_online  y_offline  y_all store_id sku_id\n",
       "582306 2023-09-01       0.0        2.0    2.0        1      1\n",
       "582307 2023-09-01       1.0        3.0    4.0        1      2\n",
       "582308 2023-09-01       3.0        4.0    7.0        1      3\n",
       "582309 2023-09-01       2.0        0.0    2.0        1      4\n",
       "582310 2023-09-01       7.0       30.0   37.0        1      5\n",
       "...           ...       ...        ...    ...      ...    ...\n",
       "750301 2023-09-14       2.0        3.0    5.0       12    996\n",
       "750302 2023-09-14       3.0        2.0    5.0       12    997\n",
       "750303 2023-09-14       2.0        1.0    3.0       12    998\n",
       "750304 2023-09-14       2.0        2.0    4.0       12    999\n",
       "750305 2023-09-14       2.0        1.0    3.0       12   1000\n",
       "\n",
       "[168000 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412.0 482.6 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(predict_df.y_offline.max(),predict_df.y_online.max(),predict_df.y_offline.min(),predict_df.y_online.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>y_online</th>\n",
       "      <th>y_offline</th>\n",
       "      <th>y_all</th>\n",
       "      <th>store_id</th>\n",
       "      <th>sku_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>582306</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582307</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582308</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582309</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582310</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750301</th>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750302</th>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750303</th>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750304</th>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750305</th>\n",
       "      <td>2023-09-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  y_online  y_offline  y_all store_id sku_id\n",
       "582306 2023-09-01       0.0        1.0    1.0        1      1\n",
       "582307 2023-09-01       1.0        3.0    4.0        1      2\n",
       "582308 2023-09-01       3.0        4.0    7.0        1      3\n",
       "582309 2023-09-01       2.0        0.0    2.0        1      4\n",
       "582310 2023-09-01       7.0       30.0   37.0        1      5\n",
       "...           ...       ...        ...    ...      ...    ...\n",
       "750301 2023-09-14       1.0        1.0    2.0       12    996\n",
       "750302 2023-09-14       1.0        1.0    2.0       12    997\n",
       "750303 2023-09-14       2.0        1.0    3.0       12    998\n",
       "750304 2023-09-14       2.0        2.0    4.0       12    999\n",
       "750305 2023-09-14       2.0        1.0    3.0       12   1000\n",
       "\n",
       "[168000 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上一个版本\n",
    "predict_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
